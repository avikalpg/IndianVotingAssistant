{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import xmltodict\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://eci.gov.in/elections/future-elections/')\n",
    "print(r.status_code)\n",
    "soup = bs(r.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['table', 'table-striped', 'table-hover']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[[],\n",
       "  [['HOUSE/STATE', 'FROM', 'TO', 'SEAT'],\n",
       "   ['GOA', '16.03.2017', '15.03.2022', '40'],\n",
       "   ['MANIPUR', '20.03.2017', '19.03.2022', '60'],\n",
       "   ['UTTARAKHAND', '24.03.2017', '23.03.2022', '70'],\n",
       "   ['PUNJAB', '28.03.2017', '27.03.2022', '117'],\n",
       "   ['UTTAR PRADESH', '15.05.2017', '14.05.2022', '403']]]]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "all_data = []\n",
    "tables = soup.find_all('table')\n",
    "for table in tables:\n",
    "    print(table['class'])\n",
    "    tdata = []\n",
    "    table_bodies = table.find_all('tbody')\n",
    "\n",
    "    for table_body in table_bodies:\n",
    "        data = []\n",
    "        rows = table_body.find_all('tr')\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) == 0:\n",
    "                cols = row.find_all('th')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "        tdata.append(data)\n",
    "    all_data.append(tdata)\n",
    "all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tr [OrderedDict([('th', ['HOUSE/STATE', 'FROM', 'TO', 'SEAT'])]), OrderedDict([('td', ['GOA', '16.03.2017', '15.03.2022', '40'])]), OrderedDict([('td', ['MANIPUR', '20.03.2017', '19.03.2022', '60'])]), OrderedDict([('td', ['UTTARAKHAND', '24.03.2017', '23.03.2022', '70'])]), OrderedDict([('td', ['PUNJAB', '28.03.2017', '27.03.2022', '117'])]), OrderedDict([('td', ['UTTAR PRADESH', '15.05.2017', '14.05.2022', '403'])])]\ntr [OrderedDict([('th', ['HOUSE/STATE', 'FROM', 'TO', 'SEAT'])]), OrderedDict([('td', ['GOA', '16.03.2017', '15.03.2022', '40'])]), OrderedDict([('td', ['MANIPUR', '20.03.2017', '19.03.2022', '60'])]), OrderedDict([('td', ['UTTARAKHAND', '24.03.2017', '23.03.2022', '70'])]), OrderedDict([('td', ['PUNJAB', '28.03.2017', '27.03.2022', '117'])]), OrderedDict([('td', ['UTTAR PRADESH', '15.05.2017', '14.05.2022', '403'])])]\ntr [OrderedDict([('th', ['HOUSE/STATE', 'FROM', 'TO', 'SEAT'])]), OrderedDict([('td', ['GOA', '16.03.2017', '15.03.2022', '40'])]), OrderedDict([('td', ['MANIPUR', '20.03.2017', '19.03.2022', '60'])]), OrderedDict([('td', ['UTTARAKHAND', '24.03.2017', '23.03.2022', '70'])]), OrderedDict([('td', ['PUNJAB', '28.03.2017', '27.03.2022', '117'])]), OrderedDict([('td', ['UTTAR PRADESH', '15.05.2017', '14.05.2022', '403'])])]\n"
     ]
    }
   ],
   "source": [
    "tables = soup.find_all('table')\n",
    "for table in tables:\n",
    "    data_dict = xmltodict.parse(table.prettify())\n",
    "    for val in data_dict.values():\n",
    "        for key in val.keys():\n",
    "            table_body = val['tbody']\n",
    "            for row in table_body:\n",
    "                if row == None:\n",
    "                    continue\n",
    "                for key in row:\n",
    "                    print(key, row[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['table', 'table-striped', 'table-hover']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[[],\n",
       "  [{'HOUSE/STATE': 'GOA',\n",
       "    'FROM': '16.03.2017',\n",
       "    'TO': '15.03.2022',\n",
       "    'SEAT': '40'},\n",
       "   {'HOUSE/STATE': 'MANIPUR',\n",
       "    'FROM': '20.03.2017',\n",
       "    'TO': '19.03.2022',\n",
       "    'SEAT': '60'},\n",
       "   {'HOUSE/STATE': 'UTTARAKHAND',\n",
       "    'FROM': '24.03.2017',\n",
       "    'TO': '23.03.2022',\n",
       "    'SEAT': '70'},\n",
       "   {'HOUSE/STATE': 'PUNJAB',\n",
       "    'FROM': '28.03.2017',\n",
       "    'TO': '27.03.2022',\n",
       "    'SEAT': '117'},\n",
       "   {'HOUSE/STATE': 'UTTAR PRADESH',\n",
       "    'FROM': '15.05.2017',\n",
       "    'TO': '14.05.2022',\n",
       "    'SEAT': '403'}]]]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "all_data = []\n",
    "tables = soup.find_all('table')\n",
    "for table in tables:\n",
    "    print(table['class'])\n",
    "    tdata = []\n",
    "    table_bodies = table.find_all('tbody')\n",
    "\n",
    "    for table_body in table_bodies:\n",
    "        data = []\n",
    "        keys = []\n",
    "        rows = table_body.find_all('tr')\n",
    "        for row in rows:\n",
    "            row_data = dict()\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) == 0:\n",
    "                cols = row.find_all('th')\n",
    "                keys = [ele.text.strip() for ele in cols]\n",
    "                continue\n",
    "            for i, ele in enumerate(cols):\n",
    "                row_data[keys[i]] = ele.text.strip()\n",
    "            data.append(row_data)\n",
    "        tdata.append(data)\n",
    "    all_data.append(tdata)\n",
    "all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "[     HOUSE/STATE        FROM          TO  SEAT\n 0            GOA  16.03.2017  15.03.2022    40\n 1        MANIPUR  20.03.2017  19.03.2022    60\n 2    UTTARAKHAND  24.03.2017  23.03.2022    70\n 3         PUNJAB  28.03.2017  27.03.2022   117\n 4  UTTAR PRADESH  15.05.2017  14.05.2022   403]"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'HOUSE/STATE': 'GOA', 'FROM': '16.03.2017', 'TO': '15.03.2022', 'SEAT': 40}, {'HOUSE/STATE': 'MANIPUR', 'FROM': '20.03.2017', 'TO': '19.03.2022', 'SEAT': 60}, {'HOUSE/STATE': 'UTTARAKHAND', 'FROM': '24.03.2017', 'TO': '23.03.2022', 'SEAT': 70}, {'HOUSE/STATE': 'PUNJAB', 'FROM': '28.03.2017', 'TO': '27.03.2022', 'SEAT': 117}, {'HOUSE/STATE': 'UTTAR PRADESH', 'FROM': '15.05.2017', 'TO': '14.05.2022', 'SEAT': 403}]\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "tables = pd.read_html(r.text)\n",
    "display(tables)\n",
    "print(tables[0].to_dict(orient='records'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}